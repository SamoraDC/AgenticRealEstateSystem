#!/usr/bin/env python3
"""
TESTE ESPEC√çFICO: Modelos Groq para Acesso aos Logs NLL

MODELOS A TESTAR:
1. llama-3.3-70b-versatile
2. meta-llama/llama-4-scout-17b-16e-instruct
3. meta-llama/llama-4-maverick-17b-128e-instruct
4. moonshotai/kimi-k2-instruct
5. qwen/qwen3-32b

OBJETIVO: Verificar qual modelo suporta logprobs para calcular NLL
"""

import os
import json
import math
import asyncio
import traceback
from typing import Dict, List, Any
from dotenv import load_dotenv

load_dotenv()

class GroqSpecificModelTester:
    """Testador espec√≠fico para modelos Groq solicitados"""
    
    def __init__(self):
        self.groq_api_key = os.getenv("GROQ_API_KEY")
        
        # Modelos espec√≠ficos solicitados
        self.models_to_test = [
            "llama-3.3-70b-versatile",
            "meta-llama/llama-4-scout-17b-16e-instruct", 
            "meta-llama/llama-4-maverick-17b-128e-instruct",
            "moonshotai/kimi-k2-instruct",
            "qwen/qwen3-32b"
        ]
        
        # Prompt de teste otimizado
        self.test_prompt = "Explain machine learning in exactly 20 words."
        
        # Configurar cliente
        if self.groq_api_key:
            try:
                from groq import Groq
                self.client = Groq(api_key=self.groq_api_key)
                print("‚úÖ Cliente Groq configurado")
            except ImportError:
                print("‚ùå Biblioteca Groq n√£o dispon√≠vel")
                self.client = None
        else:
            print("‚ùå GROQ_API_KEY n√£o encontrada")
            self.client = None
    
    def print_section(self, title: str):
        """Imprimir se√ß√£o formatada"""
        print(f"\n{'='*70}")
        print(f" {title}")
        print(f"{'='*70}")
    
    async def test_model_comprehensive(self, model_name: str) -> Dict[str, Any]:
        """Teste abrangente de um modelo espec√≠fico"""
        
        print(f"\nü§ñ TESTANDO: {model_name}")
        print("-" * 50)
        
        if not self.client:
            return {
                "model": model_name,
                "status": "error",
                "error": "Cliente Groq n√£o dispon√≠vel"
            }
        
        result = {
            "model": model_name,
            "basic_functionality": False,
            "logprobs_supported": False,
            "nll_calculable": False,
            "status": "unknown"
        }
        
        # TESTE 1: Funcionalidade b√°sica
        print("üîç Teste 1: Funcionalidade b√°sica...")
        try:
            basic_response = self.client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": self.test_prompt}],
                temperature=0.3,
                max_tokens=30
            )
            
            response_text = basic_response.choices[0].message.content
            print(f"‚úÖ Funcionalidade b√°sica OK")
            print(f"üì§ Resposta: {response_text[:60]}...")
            
            result.update({
                "basic_functionality": True,
                "response_text": response_text,
                "status": "partial"
            })
            
        except Exception as e:
            print(f"‚ùå Funcionalidade b√°sica FALHOU: {e}")
            result.update({
                "status": "error",
                "error": str(e)
            })
            return result
        
        # TESTE 2: Suporte a logprobs
        print("\nüîç Teste 2: Suporte a logprobs...")
        try:
            logprobs_response = self.client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": self.test_prompt}],
                temperature=0.1,
                max_tokens=30,
                logprobs=True,
                top_logprobs=5
            )
            
            print("‚úÖ Logprobs suportados!")
            result["logprobs_supported"] = True
            
            # TESTE 3: An√°lise detalhada dos logprobs
            print("\nüîç Teste 3: An√°lise de logprobs...")
            choice = logprobs_response.choices[0]
            
            if hasattr(choice, 'logprobs') and choice.logprobs:
                logprobs = choice.logprobs
                print(f"üìä Estrutura logprobs: {type(logprobs)}")
                
                # Verificar atributos do logprobs
                logprobs_attrs = []
                for attr in dir(logprobs):
                    if not attr.startswith('_'):
                        try:
                            value = getattr(logprobs, attr)
                            if not callable(value):
                                logprobs_attrs.append(f"{attr}: {type(value)}")
                        except:
                            continue
                
                print(f"üìã Atributos logprobs: {logprobs_attrs}")
                
                # Verificar tokens individuais
                if hasattr(logprobs, 'content') and logprobs.content:
                    print(f"üéØ TOKENS ENCONTRADOS: {len(logprobs.content)}")
                    
                    total_logprob = 0.0
                    token_details = []
                    
                    for i, token_logprob in enumerate(logprobs.content):
                        if i < 5:  # Mostrar apenas primeiros 5 tokens
                            token = getattr(token_logprob, 'token', 'N/A')
                            logprob = getattr(token_logprob, 'logprob', 0.0)
                            
                            print(f"  Token {i}: '{token}' -> logprob: {logprob:.4f}")
                            
                            total_logprob += logprob
                            token_details.append({
                                "token": token,
                                "logprob": logprob
                            })
                            
                            # Verificar alternativas
                            if hasattr(token_logprob, 'top_logprobs') and token_logprob.top_logprobs:
                                print(f"    üîÑ Alternativas:")
                                for j, alt in enumerate(token_logprob.top_logprobs[:3]):
                                    alt_token = getattr(alt, 'token', 'N/A')
                                    alt_logprob = getattr(alt, 'logprob', 0.0)
                                    print(f"      {j+1}. '{alt_token}': {alt_logprob:.4f}")
                    
                    # CALCULAR NLL
                    if token_details:
                        nll = -total_logprob
                        perplexity = math.exp(nll / len(token_details))
                        
                        result.update({
                            "nll_calculable": True,
                            "status": "success",
                            "nll_value": nll,
                            "perplexity": perplexity,
                            "token_count": len(logprobs.content),
                            "total_logprob": total_logprob,
                            "token_details": token_details,
                            "logprobs_response_text": choice.message.content
                        })
                        
                        print(f"\nüìä M√âTRICAS CALCULADAS:")
                        print(f"    ‚úÖ NLL: {nll:.4f}")
                        print(f"    ‚úÖ Perplexity: {perplexity:.4f}")
                        print(f"    ‚úÖ Tokens analisados: {len(logprobs.content)}")
                        print(f"    ‚úÖ Total logprob: {total_logprob:.4f}")
                
            else:
                print("‚ùå Logprobs n√£o encontrados na resposta")
                
        except Exception as e:
            print(f"‚ùå Logprobs N√ÉO suportados: {e}")
            result["logprobs_error"] = str(e)
        
        return result
    
    async def test_all_models(self) -> List[Dict[str, Any]]:
        """Testar todos os modelos solicitados"""
        
        self.print_section("TESTE DE MODELOS GROQ ESPEC√çFICOS")
        
        print(f"üéØ Testando {len(self.models_to_test)} modelos para acesso aos logs NLL")
        print(f"üìù Prompt de teste: {self.test_prompt}")
        
        results = []
        
        for model_name in self.models_to_test:
            result = await self.test_model_comprehensive(model_name)
            results.append(result)
            
            # Pausa entre testes para n√£o sobrecarregar a API
            await asyncio.sleep(1)
        
        return results
    
    def analyze_results(self, results: List[Dict[str, Any]]):
        """Analisar e apresentar resultados finais"""
        
        self.print_section("AN√ÅLISE FINAL DOS RESULTADOS")
        
        # Categorizar resultados
        working_models = []
        logprobs_models = []
        nll_models = []
        error_models = []
        
        print("üìä RESUMO POR MODELO:\n")
        
        for result in results:
            model = result["model"]
            status = result["status"]
            
            print(f"ü§ñ {model}:")
            
            if status == "success":
                print(f"   ‚úÖ Status: TOTALMENTE FUNCIONAL")
                print(f"   ‚úÖ Funcionalidade b√°sica: SIM")
                print(f"   ‚úÖ Logprobs: SIM")
                print(f"   ‚úÖ NLL calcul√°vel: SIM")
                print(f"   üìä NLL: {result['nll_value']:.4f}")
                print(f"   üìä Perplexity: {result['perplexity']:.4f}")
                print(f"   üìä Tokens: {result['token_count']}")
                
                working_models.append(model)
                logprobs_models.append(model)
                nll_models.append((model, result['nll_value']))
                
            elif status == "partial":
                print(f"   ‚ö†Ô∏è Status: PARCIALMENTE FUNCIONAL")
                print(f"   ‚úÖ Funcionalidade b√°sica: SIM")
                print(f"   ‚ùå Logprobs: N√ÉO")
                print(f"   ‚ùå NLL calcul√°vel: N√ÉO")
                
                working_models.append(model)
                
            else:
                print(f"   ‚ùå Status: N√ÉO FUNCIONAL")
                print(f"   ‚ùå Erro: {result.get('error', 'Desconhecido')}")
                
                error_models.append((model, result.get('error', 'Desconhecido')))
            
            print()
        
        # Estat√≠sticas finais
        self.print_section("ESTAT√çSTICAS FINAIS")
        
        total_models = len(results)
        print(f"üìà RESUMO ESTAT√çSTICO:")
        print(f"   ü§ñ Total de modelos testados: {total_models}")
        print(f"   ‚úÖ Modelos funcionais: {len(working_models)}")
        print(f"   üìä Com suporte a logprobs: {len(logprobs_models)}")
        print(f"   üéØ NLL calcul√°vel: {len(nll_models)}")
        print(f"   ‚ùå Com erros: {len(error_models)}")
        
        # Recomenda√ß√µes espec√≠ficas
        print(f"\nüí° RECOMENDA√á√ïES:")
        
        if nll_models:
            print(f"üèÜ MODELOS RECOMENDADOS PARA NLL:")
            # Ordenar por melhor NLL (menor valor)
            for model, nll_value in sorted(nll_models, key=lambda x: x[1]):
                print(f"   ‚≠ê {model}: NLL = {nll_value:.4f}")
        else:
            print(f"‚ùå NENHUM MODELO SUPORTA C√ÅLCULO DIRETO DE NLL")
        
        if logprobs_models:
            print(f"\n‚úÖ MODELOS COM LOGPROBS:")
            for model in logprobs_models:
                print(f"   üìä {model}")
        
        if working_models and not logprobs_models:
            print(f"\n‚ö†Ô∏è MODELOS APENAS COM FUNCIONALIDADE B√ÅSICA:")
            basic_only = [m for m in working_models if m not in logprobs_models]
            for model in basic_only:
                print(f"   üîß {model}")
        
        if error_models:
            print(f"\n‚ùå MODELOS COM PROBLEMAS:")
            for model, error in error_models:
                print(f"   üö´ {model}: {error}")
        
        return {
            "total_tested": total_models,
            "working_models": working_models,
            "logprobs_models": logprobs_models,
            "nll_models": nll_models,
            "error_models": error_models
        }
    
    async def run_comprehensive_test(self):
        """Executar teste completo"""
        
        print("üß™ TESTE ESPEC√çFICO DE MODELOS GROQ PARA NLL")
        print("=" * 70)
        print("Verificando acesso aos logs para c√°lculo de Negative Log Likelihood")
        
        # Testar todos os modelos
        results = await self.test_all_models()
        
        # Analisar resultados
        summary = self.analyze_results(results)
        
        # Salvar resultados detalhados
        output_data = {
            "test_info": {
                "prompt": self.test_prompt,
                "models_tested": self.models_to_test,
                "timestamp": "2024-12-19"
            },
            "results": results,
            "summary": summary
        }
        
        try:
            with open("groq_specific_models_nll_test.json", 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False, default=str)
            print(f"\nüíæ Resultados detalhados salvos em: groq_specific_models_nll_test.json")
        except Exception as e:
            print(f"‚ùå Erro ao salvar resultados: {e}")
        
        return results

async def main():
    """Fun√ß√£o principal"""
    
    tester = GroqSpecificModelTester()
    results = await tester.run_comprehensive_test()
    
    print(f"\nüèÅ Teste espec√≠fico de modelos Groq conclu√≠do!")
    print(f"üìÅ Verifique os resultados detalhados no arquivo JSON gerado.")

if __name__ == "__main__":
    asyncio.run(main()) 