#!/usr/bin/env python3
"""
CALCULADORA FINAL DE NLL - Solu√ß√£o Otimizada para Google Gemini + Groq

CONCLUS√ÉO DOS TESTES:
- Google Gemini 2.0 Flash Lite: ‚úÖ Funciona, mas logprobs limitados  
- Groq LLaMA 4 Scout: ‚ùå Erro 500 / Sem suporte a logprobs

SOLU√á√ÉO IMPLEMENTADA:
- Estima√ß√£o de NLL via sampling m√∫ltiplo com Google Gemini
- Fallback para aproxima√ß√£o matem√°tica
- Interface simples para uso em produ√ß√£o
"""

import os
import json
import math
import asyncio
from typing import Dict, Any, List
from dotenv import load_dotenv

load_dotenv()

class ProductionNLLCalculator:
    """Calculadora de NLL otimizada para produ√ß√£o"""
    
    def __init__(self):
        self.google_api_key = os.getenv("GOOGLE_API_KEY")
        self.groq_api_key = os.getenv("GROQ_API_KEY")
        
        # Configurar cliente Google
        if self.google_api_key:
            try:
                import google.generativeai as genai
                genai.configure(api_key=self.google_api_key)
                self.model = genai.GenerativeModel('gemini-2.0-flash-lite')
                print("‚úÖ Google Gemini configurado")
            except ImportError:
                print("‚ùå google-generativeai n√£o instalado")
                self.model = None
        else:
            print("‚ùå GOOGLE_API_KEY n√£o encontrada")
            self.model = None
    
    async def calculate_nll_production(self, text: str, method: str = "auto") -> Dict[str, Any]:
        """
        Calcular NLL usando o melhor m√©todo dispon√≠vel
        
        Args:
            text: Texto para calcular NLL
            method: "auto", "sampling", "mathematical"
        
        Returns:
            Dict com resultado do c√°lculo
        """
        
        if method == "auto":
            # Escolher melhor m√©todo automaticamente
            if self.model:
                return await self._calculate_via_sampling(text)
            else:
                return self._calculate_mathematical(text)
        elif method == "sampling":
            return await self._calculate_via_sampling(text)
        elif method == "mathematical":
            return self._calculate_mathematical(text)
        else:
            return {"error": f"M√©todo '{method}' n√£o reconhecido"}
    
    async def _calculate_via_sampling(self, text: str, num_samples: int = 10) -> Dict[str, Any]:
        """Calcular NLL via amostragem m√∫ltipla com Google Gemini"""
        
        if not self.model:
            return {"error": "Modelo Google n√£o dispon√≠vel"}
        
        try:
            import google.generativeai as genai
            
            print(f"üé≤ Calculando NLL via {num_samples} amostras...")
            
            # Prompt base para teste de probabilidade
            base_prompt = f"Continue este texto de forma natural: '{text}'"
            
            # Gerar amostras com diferentes temperaturas
            temperatures = [0.1, 0.3, 0.5, 0.7, 0.9]
            samples = []
            target_words = set(text.lower().split())
            
            for temp in temperatures:
                samples_per_temp = num_samples // len(temperatures)
                
                for i in range(samples_per_temp):
                    try:
                        response = self.model.generate_content(
                            base_prompt,
                            generation_config=genai.types.GenerationConfig(
                                temperature=temp,
                                max_output_tokens=len(text.split()) + 10,
                                candidate_count=1
                            )
                        )
                        
                        generated_text = response.text.strip()
                        similarity = self._calculate_text_similarity(generated_text, text)
                        
                        samples.append({
                            "temperature": temp,
                            "generated": generated_text,
                            "similarity": similarity,
                            "contains_target": any(word in generated_text.lower() for word in target_words)
                        })
                        
                    except Exception as e:
                        print(f"‚ö†Ô∏è Erro na amostra T={temp}, i={i}: {e}")
                        continue
            
            if not samples:
                return {"error": "Nenhuma amostra v√°lida gerada"}
            
            # Calcular m√©tricas de probabilidade
            high_similarity_samples = [s for s in samples if s["similarity"] > 0.6]
            contains_target_samples = [s for s in samples if s["contains_target"]]
            
            # Estimativa de probabilidade baseada em similaridade
            similarity_prob = len(high_similarity_samples) / len(samples)
            target_prob = len(contains_target_samples) / len(samples)
            
            # Combinar evid√™ncias para probabilidade final
            combined_prob = (similarity_prob * 0.7) + (target_prob * 0.3)
            combined_prob = max(combined_prob, 1e-10)  # Evitar log(0)
            
            # Calcular NLL
            estimated_nll = -math.log(combined_prob)
            estimated_perplexity = math.exp(estimated_nll)
            
            # M√©tricas adicionais
            avg_similarity = sum(s["similarity"] for s in samples) / len(samples)
            avg_temp = sum(s["temperature"] for s in samples) / len(samples)
            
            return {
                "status": "success",
                "method": "sampling_estimation",
                "nll_value": estimated_nll,
                "perplexity": estimated_perplexity,
                "probability_estimate": combined_prob,
                "samples_analyzed": len(samples),
                "high_similarity_count": len(high_similarity_samples),
                "target_match_count": len(contains_target_samples),
                "avg_similarity": avg_similarity,
                "avg_temperature": avg_temp,
                "text_analyzed": text,
                "sample_details": samples[:3]  # Primeiras 3 amostras para debug
            }
            
        except Exception as e:
            return {"error": f"Erro na estima√ß√£o por sampling: {e}"}
    
    def _calculate_mathematical(self, text: str) -> Dict[str, Any]:
        """Aproxima√ß√£o matem√°tica r√°pida de NLL"""
        
        try:
            # An√°lise b√°sica do texto
            char_count = len(text)
            word_count = len(text.split())
            unique_words = len(set(text.lower().split()))
            
            # C√°lculo de entropia estimada (baseado em estudos lingu√≠sticos)
            # Refer√™ncia: Shannon (1951) - ~4.5 bits por caractere em ingl√™s
            entropy_per_char = 4.5
            
            if any(ord(c) > 127 for c in text):  # Caracteres n√£o-ASCII
                entropy_per_char = 5.2
            
            # Calcular entropia total
            total_entropy_bits = char_count * entropy_per_char
            total_entropy_nats = total_entropy_bits * math.log(2)
            
            # Fatores de corre√ß√£o
            repetition_factor = word_count / unique_words if unique_words > 0 else 1
            complexity_factor = 1.0
            
            # Ajustes baseados na estrutura do texto
            if text.count('.') > 0:
                complexity_factor *= 0.95  # Senten√ßas completas s√£o mais previs√≠veis
            if any(c.isupper() for c in text):
                complexity_factor *= 0.92  # Capitaliza√ß√£o adiciona previsibilidade
            if any(c.isdigit() for c in text):
                complexity_factor *= 1.08  # N√∫meros s√£o menos previs√≠veis
            
            # NLL final ajustado
            approximate_nll = (total_entropy_nats * complexity_factor) / repetition_factor
            approximate_perplexity = math.exp(approximate_nll / word_count)
            
            return {
                "status": "success",
                "method": "mathematical_approximation",
                "nll_value": approximate_nll,
                "perplexity": approximate_perplexity,
                "char_count": char_count,
                "word_count": word_count,
                "unique_words": unique_words,
                "repetition_factor": repetition_factor,
                "complexity_factor": complexity_factor,
                "entropy_per_char": entropy_per_char,
                "text_analyzed": text
            }
            
        except Exception as e:
            return {"error": f"Erro na aproxima√ß√£o matem√°tica: {e}"}
    
    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """Calcular similaridade entre textos usando m√∫ltiplas m√©tricas"""
        
        # Similaridade por palavras (Jaccard)
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 and not words2:
            return 1.0
        
        jaccard = len(words1.intersection(words2)) / len(words1.union(words2)) if words1.union(words2) else 0.0
        
        # Similaridade por caracteres (overlap)
        chars1 = set(text1.lower())
        chars2 = set(text2.lower())
        char_similarity = len(chars1.intersection(chars2)) / len(chars1.union(chars2)) if chars1.union(chars2) else 0.0
        
        # Similaridade por comprimento
        len_similarity = 1.0 - abs(len(text1) - len(text2)) / max(len(text1), len(text2), 1)
        
        # Combinar m√©tricas
        combined_similarity = (jaccard * 0.6) + (char_similarity * 0.2) + (len_similarity * 0.2)
        return combined_similarity
    
    async def compare_methods(self, text: str) -> Dict[str, Any]:
        """Comparar diferentes m√©todos de c√°lculo de NLL"""
        
        print(f"üîÑ Comparando m√©todos para: '{text}'")
        
        results = {}
        
        # M√©todo 1: Sampling
        if self.model:
            sampling_result = await self._calculate_via_sampling(text, num_samples=8)
            results["sampling"] = sampling_result
        
        # M√©todo 2: Matem√°tico
        math_result = self._calculate_mathematical(text)
        results["mathematical"] = math_result
        
        # An√°lise comparativa
        if "sampling" in results and results["sampling"].get("status") == "success":
            sampling_nll = results["sampling"]["nll_value"]
            math_nll = results["mathematical"]["nll_value"]
            
            diff = abs(sampling_nll - math_nll)
            ratio = sampling_nll / math_nll
            
            results["comparison"] = {
                "sampling_nll": sampling_nll,
                "mathematical_nll": math_nll,
                "absolute_difference": diff,
                "ratio": ratio,
                "recommended_method": "sampling" if sampling_nll < math_nll * 2 else "mathematical"
            }
        
        return results

# Interface simples para uso
async def calculate_nll(text: str, method: str = "auto") -> float:
    """
    Interface simples para calcular NLL
    
    Args:
        text: Texto para an√°lise
        method: "auto", "sampling", "mathematical"
    
    Returns:
        Valor do NLL calculado
    """
    calculator = ProductionNLLCalculator()
    result = await calculator.calculate_nll_production(text, method)
    
    if result.get("status") == "success":
        return result["nll_value"]
    else:
        raise Exception(f"Erro no c√°lculo: {result.get('error')}")

# Demonstra√ß√£o e testes
async def main():
    """Demonstra√ß√£o da calculadora de NLL"""
    
    print("üßÆ CALCULADORA FINAL DE NLL")
    print("=" * 50)
    
    calculator = ProductionNLLCalculator()
    
    # Textos de teste
    test_texts = [
        "Machine learning enables computers to learn patterns from data.",
        "The future of artificial intelligence in real estate will be transformative.",
        "Hello world, this is a simple test.",
        "Complex mathematical equations require sophisticated computational approaches."
    ]
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nüìù TESTE {i}: {text}")
        print("-" * 50)
        
        # Comparar m√©todos
        results = await calculator.compare_methods(text)
        
        for method, result in results.items():
            if method == "comparison":
                print(f"\nüìä COMPARA√á√ÉO:")
                print(f"   Sampling NLL: {result['sampling_nll']:.4f}")
                print(f"   Matem√°tico NLL: {result['mathematical_nll']:.4f}")
                print(f"   Diferen√ßa: {result['absolute_difference']:.4f}")
                print(f"   üèÜ Recomendado: {result['recommended_method']}")
            elif result.get("status") == "success":
                nll = result["nll_value"]
                perplexity = result["perplexity"]
                print(f"   {method.upper()}: NLL = {nll:.4f}, Perplexity = {perplexity:.2f}")
            else:
                print(f"   {method.upper()}: ‚ùå {result.get('error')}")
    
    # Exemplo de uso simples
    print(f"\nüöÄ EXEMPLO DE USO SIMPLES:")
    print("-" * 30)
    
    exemplo_texto = "Artificial intelligence transforms modern technology."
    nll_simples = await calculate_nll(exemplo_texto)
    print(f"NLL para '{exemplo_texto}': {nll_simples:.4f}")
    
    print(f"\n‚úÖ Calculadora de NLL pronta para uso!")
    print(f"üí° Use: await calculate_nll('seu texto aqui')")

if __name__ == "__main__":
    asyncio.run(main()) 